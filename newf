import speech_recognition as sr
import pyttsx3
import threading
import queue
import time
import os
from google.cloud import aiplatform
from google.cloud.aiplatform.gapic import PredictionServiceClient
from google.cloud.aiplatform_v1.types import PredictRequest
from google.protobuf import json_format

# Initialize TTS engine with ALSA for Raspberry Pi
os.environ["PYTTSX3_BACKEND"] = "espeak"  # Use eSpeak for Raspberry Pi compatibility
tts_engine = pyttsx3.init()
tts_engine.setProperty('rate', 150)
tts_engine.setProperty('voice', 'english')  # Set default English voice

# Queue and flags
speech_queue = queue.Queue()
stop_speaking = threading.Event()
speaking = threading.Event()
conversation_history = []

# Microphone index (update based on your Raspberry Pi's microphone)
MIC_INDEX = 0  # Adjust after running and checking available microphones

# List available microphones
for index, name in enumerate(sr.Microphone.list_microphone_names()):
    print(f"{index}: {name}")

def recognize_speech(timeout=0.05, phrase_time_limit=5, is_activation=False, is_question=False):
    r = sr.Recognizer()
    with sr.Microphone(device_index=MIC_INDEX) as source:
        r.dynamic_energy_threshold = True
        r.adjust_for_ambient_noise(source, duration=1)  # Calibrate for ambient noise
        try:
            effective_timeout = 1.0 if is_activation else (0.5 if is_question else timeout)
            audio = r.listen(source, timeout=effective_timeout, phrase_time_limit=phrase_time_limit)
            return r.recognize_google(audio).lower()  # Using Google Speech API
        except (sr.WaitTimeoutError, sr.UnknownValueError):
            return None
        except sr.RequestError as e:
            print(f"Speech recognition error: {e}")
            return None

def recognize_question():
    r = sr.Recognizer()
    full_text = []
    silence_timeout = 2.0
    max_total_duration = 20

    with sr.Microphone(device_index=MIC_INDEX) as source:
        r.dynamic_energy_threshold = True
        r.pause_threshold = silence_timeout
        r.adjust_for_ambient_noise(source, duration=1)
        start_time = time.time()

        print("Recording speech...")

        while time.time() - start_time < max_total_duration:
            try:
                audio = r.listen(source, timeout=3, phrase_time_limit=10)
                try:
                    text = r.recognize_google(audio).lower()
                    if text:
                        full_text.append(text)
                        print(f"Captured chunk: {text}")
                except sr.UnknownValueError:
                    pass
            except sr.WaitTimeoutError:
                break

        final_text = " ".join(full_text).strip()
        return final_text if final_text else None

def process_with_gemini(text):
    try:
        # Replace with your Google Cloud project ID and Gemini API endpoint
        project_id = "YOUR_PROJECT_ID"  # Set up in Google Cloud Console
        location = "us-central1"  # Adjust if needed
        endpoint_id = "gemini-1.5-flash"  # Use Gemini 1.5 Flash for free tier

        # Initialize Google Cloud AI Platform client
        client = PredictionServiceClient()
        endpoint = f"projects/{project_id}/locations/{location}/publishers/google/models/{endpoint_id}"

        prompt = (
            f"Provide a detailed response to the question: {text}. "
            f"Context: {', '.join(conversation_history[-10:]) if conversation_history else 'none'}. "
            "If the question is inappropriate or not related to studies or productivity, respond with 'please don’t waste your future, study'. "
            "Only respond in English. If the request is in another language, respond with 'I only support English for now.'"
        )

        # Prepare the request
        instance = {"prompt": prompt}
        instance = json_format.ParseDict(instance, {})
        request = PredictRequest(endpoint=endpoint, instances=[instance])

        # Make the API call
        response = client.predict(request=request)
        result = response.predictions[0].content if response.predictions else "Sorry, I can’t answer that."
        return result
    except Exception as e:
        print(f"Gemini API error: {e}")
        return "Sorry, I can’t answer that right now."

def speak_text(text):
    global tts_engine
    if stop_speaking.is_set():
        return
    speaking.set()
    try:
        if not tts_engine._inLoop:
            tts_engine = pyttsx3.init()
            tts_engine.setProperty('rate', 150)
            tts_engine.setProperty('voice', 'english')
        tts_engine.say(text)
        tts_engine.runAndWait()
    except Exception as e:
        print(f"TTS error: {e}")
        try:
            tts_engine = pyttsx3.init()
            tts_engine.setProperty('rate', 150)
            tts_engine.setProperty('voice', 'english')
        except Exception as e:
            print(f"TTS reinitialization error: {e}")
    finally:
        speaking.clear()

def listen_for_activation():
    global tts_engine
    activation_phrases = ["hey steve", "steve", "hi steve"]
    while True:
        print("Listening for activation...")
        recognized_text = recognize_speech(timeout=0.05, phrase_time_limit=5, is_activation=True)
        if recognized_text and any(phrase in recognized_text for phrase in activation_phrases):
            print(f"You: {recognized_text}")
            stop_speaking.set()
            try:
                tts_engine.stop()
            except Exception as e:
                print(f"TTS stop error: {e}")
            stop_speaking.clear()

            while True:
                print("Listening for questions...")
                question_text = recognize_question()
                if question_text:
                    print(f"You: {question_text}")
                    ai_response = process_with_gemini(question_text)
                    print(f"AI: {ai_response}")

                    conversation_history.extend([f"Q: {question_text}", f"A: {ai_response}"])
                    if len(conversation_history) > 10:
                        conversation_history[:] = conversation_history[-10:]

                    speak_thread = threading.Thread(target=speak_text, args=(ai_response,))
                    speak_thread.start()

                    while speak_thread.is_alive():
                        interrupt_text = recognize_speech(timeout=0.05, phrase_time_limit=5, is_activation=True)
                        if interrupt_text and any(phrase in interrupt_text for phrase in activation_phrases):
                            stop_speaking.set()
                            try:
                                tts_engine.stop()
                            except Exception as e:
                                print(f"TTS stop error: {e}")
                            speak_thread.join(timeout=0.5)
                            stop_speaking.clear()
                            try:
                                tts_engine.endLoop()
                            except Exception:
                                pass
                            try:
                                tts_engine = pyttsx3.init()
                                tts_engine.setProperty('rate', 150)
                                tts_engine.setProperty('voice', 'english')
                            except Exception as e:
                                print(f"TTS reinitialization error: {e}")
                            break
                else:
                    continue

if __name__ == "__main__":
    # Ensure ALSA is configured for Raspberry Pi
    os.environ["ALSA_LOG_LEVEL"] = "0"  # Suppress ALSA logs
    try:
        listen_thread = threading.Thread(target=listen_for_activation, daemon=True)
        listen_thread.start()
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("Shutting down...")
        stop_speaking.set()
        try:
            tts_engine.stop()
        except Exception as e:
            print(f"TTS stop error: {e}")